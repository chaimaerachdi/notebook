{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaimaerachdi/notebook/blob/main/Copy_of_Tp_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeV8A9bHvurr"
      },
      "source": [
        "https://www.kaggle.com/code/abdulrahmanatef/start-with-text-preprocessing#Conversion-of-Emoticon-to-Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dlc-OHWkohYI"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXb0wpi-nLYT",
        "outputId": "e6975b22-7237-4b4c-cf20-1c311a035f07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "customer-support-on-twitter.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d thoughtvector/customer-support-on-twitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeFvn7OLuCt_",
        "outputId": "866d8a37-cc6d-4fd3-a7da-596e95f6e5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/customer-support-on-twitter.zip\n",
            "  inflating: sample.csv              \n",
            "  inflating: twcs/twcs.csv           \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/customer-support-on-twitter.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65Si_bPNuSyu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-JvVb3pvp1D"
      },
      "outputs": [],
      "source": [
        "#NLTK, Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arZVsjfvuWs-"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/sample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1R1ZgN1z_5e4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz0BCV_yuK3d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKcNYwNBxR9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295dd76d-cc16-4a6b-eedb-74a557569134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   tweet_id     author_id  inbound                      created_at  \\\n",
            "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
            "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
            "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
            "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
            "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
            "\n",
            "                                                text response_tweet_id  \\\n",
            "0  @AppleSupport causing the reply to be disregar...            119236   \n",
            "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
            "2  @76328 I really hope you all change but I'm su...            119238   \n",
            "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
            "4  @VirginTrains see attached error message. I've...            119243   \n",
            "\n",
            "   in_response_to_tweet_id  \n",
            "0                      NaN  \n",
            "1                 119239.0  \n",
            "2                      NaN  \n",
            "3                 119242.0  \n",
            "4                 119240.0  \n",
            "   tweet_id                                               text  \\\n",
            "0    119237  @AppleSupport causing the reply to be disregar...   \n",
            "1    119238  @105835 Your business means a lot to us. Pleas...   \n",
            "2    119239  @76328 I really hope you all change but I'm su...   \n",
            "3    119240  @105836 LiveChat is online at the moment - htt...   \n",
            "4    119241  @VirginTrains see attached error message. I've...   \n",
            "\n",
            "                                        text_cleaned  \n",
            "0  applesupport caus repli disregard tap notif ke...  \n",
            "1  105835 busi mean lot us pleas dm name zip code...  \n",
            "2          76328 realli hope chang im sure wont dont  \n",
            "3  105836 livechat onlin moment httpstcosy94vtu8k...  \n",
            "4  virgintrain see attach error messag ive tri le...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Téléchargez le dataset depuis Kaggle\n",
        "# Assurez-vous d'ajuster le chemin du fichier CSV selon votre emplacement\n",
        "df=pd.read_csv('/content/sample.csv')\n",
        "# Affichez les premières lignes pour comprendre la structure du dataset\n",
        "print(df.head())\n",
        "\n",
        "# Mise en minuscules\n",
        "df['text_cleaned'] = df['text'].str.lower()\n",
        "\n",
        "# Suppression des ponctuations\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
        "\n",
        "# Suppression des mots vides (stopwords)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "\n",
        "# Stemming\n",
        "stemmer = PorterStemmer()\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
        "\n",
        "# Lemmatisation\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "#df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
        "\n",
        "# Suppression des émojis, émoticônes, URL, balises HTML\n",
        "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: re.sub(r'<.*?>|[^a-zA-Z0-9\\s]|:\\)|:-\\)|:\\(|:-\\(', '', x))\n",
        "\n",
        "# Affichez le dataframe résultant\n",
        "print(df[['tweet_id', 'text', 'text_cleaned']].head())\n",
        "\n",
        "# Poussez votre notebook sur GitHub en utilisant Git\n",
        "# Assurez-vous d'initialiser un dépôt git dans votre projet et de le lier à votre compte GitHub\n",
        "# Vous pouvez utiliser les commandes suivantes :\n",
        "##git config --global user.name \"chaimae\"\n",
        "#!git init\n",
        "#!git add .\n",
        "#!git commit -m \"Initial commit\"\n",
        "#!git remote add origin https://github.com/chaimaerachdi\n",
        "#!git push -u origin master\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}